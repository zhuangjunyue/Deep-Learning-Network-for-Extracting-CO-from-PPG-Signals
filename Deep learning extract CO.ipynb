{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.13 搭建深度学习网络提取CO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将figure文件夹中的图像按日期转化为张量形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\"\"\"对图像预处理 转化为张量\n",
    "   RGBA转化为RGB通道\n",
    "   图像缩放\n",
    "   对图像每个通道数据归一化\n",
    "   张量堆叠 每五个图像一轮输出张量堆叠作为网络输入\n",
    "   输出张量打印形状检查\n",
    "   存储于D：/deep learning torch\n",
    "\"\"\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  #图像缩放\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  #对图像每个通道的数据进行归一化处理\n",
    "\n",
    "])\n",
    "\n",
    "def load_and_stack_images(image_folder):\n",
    "    \"\"\"加载图像，每五个图像堆叠成一个张量\"\"\"\n",
    "    image_tensors = []\n",
    "    stacked_tensors = []\n",
    "\n",
    "    # 遍历文件夹并加载图像\n",
    "    for image_file in sorted(os.listdir(image_folder)):\n",
    "        if image_file.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_folder, image_file)\n",
    "            with Image.open(image_path).convert(\"RGB\") as img:\n",
    "                img_tensor = transform(img)\n",
    "                image_tensors.append(img_tensor)\n",
    "\n",
    "                # 当达到五个图像时，堆叠它们并重置列表\n",
    "                if len(image_tensors) == 5:\n",
    "                    stacked_tensors.append(torch.stack(image_tensors))\n",
    "                    image_tensors = []\n",
    "\n",
    "    return stacked_tensors\n",
    "\n",
    "# 主图像文件夹和保存张量的目录\n",
    "main_directory = \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\figure\"\n",
    "save_directory = \"D:\\\\deep learning torch\"\n",
    "\n",
    "# 创建保存目录\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# 加载图像并堆叠\n",
    "for date_folder in os.listdir(main_directory):\n",
    "    date_folder_path = os.path.join(main_directory, date_folder)\n",
    "    if os.path.isdir(date_folder_path):\n",
    "        stacked_image_groups = load_and_stack_images(date_folder_path)\n",
    "\n",
    "        # 处理每组堆叠的图像张量\n",
    "        for i, images_tensor in enumerate(stacked_image_groups):\n",
    "            tensor_shape = images_tensor.shape\n",
    "            print(f\"Date: {date_folder}, Group: {i}, Tensor Shape: {tensor_shape}\")\n",
    "\n",
    "            # 保存张量到D盘目录\n",
    "            tensor_filename = f\"{date_folder}_group_{i}.pt\"\n",
    "            tensor_save_path = os.path.join(save_directory, tensor_filename)\n",
    "            torch.save(images_tensor, tensor_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历data文件夹 提取excel文件中指定列数据 同时提取CO列作为标签数据 将excel表中每一列数据进行归一化 同时将数据信息与张量信息进行融合 输出新张量 作为网络的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 归一化函数\n",
    "def normalize_dataframe(df):\n",
    "    for column in df.columns:\n",
    "    \n",
    "            min_value = df[column].min()\n",
    "            max_value = df[column].max()\n",
    "            df[column] = (df[column] - min_value) / (max_value - min_value)\n",
    "    return df\n",
    "\n",
    "# 指定的列名，包括CO列\n",
    "columns_of_interest = ['Average Heartbeat Interval 3.12 (s)', 'Heartbeat Period Variability 3.12', 'R1 AC/DC Component Ratio 3.12', 'Dicrotic Notch Component to DC Component Ratio 3.12', 'ln Average DC Component 3.12', 'R1', 'R2', 'R3', 'R4', 'PPG Pulse Wave Dynamics Parameters 3.12', 'CO']\n",
    "\n",
    "# 文件夹路径\n",
    "tensor_directory = \"D:\\\\deep learning torch\"\n",
    "data_directory = \"C:\\\\Users\\\\HUAWEI\\\\Desktop\\\\data\"\n",
    "output_directory = \"D:\\\\path_to_save_results\"\n",
    "output_file_name = \"results.txt\"\n",
    "output_path = os.path.join(output_directory, output_file_name)\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# 准备用于保存结果的文件\n",
    "with open(output_path, 'w') as output_file:\n",
    "     for data_file in os.listdir(data_directory):\n",
    "            if data_file.endswith(\".xlsx\"):\n",
    "                # 从数据文件名构造图像张量文件夹的名称\n",
    "                day = os.path.splitext(data_file)[0]  # 提取文件名（不包括扩展名）\n",
    "                tensor_folder_name = f\"figure{day}\"  # 构造图像文件夹名称\n",
    "\n",
    "                data_path = os.path.join(data_directory, data_file)\n",
    "                df = pd.read_excel(data_path, usecols=columns_of_interest)\n",
    "                df_normalized = normalize_dataframe(df)\n",
    "\n",
    "                for index, row in df_normalized.iterrows():\n",
    "                    tensor_file_name = f\"{tensor_folder_name}_group_{index}.pt\"\n",
    "                    tensor_file_path = os.path.join(tensor_directory, tensor_file_name)\n",
    "                    if os.path.exists(tensor_file_path):\n",
    "                        image_tensor = torch.load(tensor_file_path)\n",
    "                        co_label = row['CO']  # 提取CO列的值\n",
    "    \n",
    "                        output_file.write(f\"Date: {tensor_folder_name}, Group: {index}, Tensor Shape: {image_tensor.shape}, Data: {row.drop('CO').to_dict()}, CO Label: {co_label}\\n\")\n",
    "\n",
    "print(f\"Results saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个数据加载器 加载器在训练过程中将张量数据以及标签提供给网络：创建自定义的Dataset类 这个类读取对应的图像张量和数值数据 作为网络输入返回\n",
    "DataLoader在训练循环中批量加载数据 在训练循环中使用 DataLoader 获取数据和对应的CO标签 输入到网络中进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建Dataset 读取对应图像张量与数值数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建并使用 CustomDataset 类 输入网络的张量动态地在每次调用 __getitem__ 方法时被加载和返回 在 CustomDataset 类 self.data 属性存储了数据文件路径 数值数据 CO标签的元组 而实际的图像张量是在调用 __getitem__ 方法时从文件中加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CustomDataset 被用来从指定的目录中加载数据  通过 DataLoader 进行批量处理 在训练循环中 遍历 data_loader 来获取每个批次的数据 并将其输入到模型中进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_directory, tensor_directory, columns_of_interest):\n",
    "        self.tensor_directory = tensor_directory\n",
    "        self.data = []\n",
    "\n",
    "        # 处理每个文件\n",
    "        for data_file in os.listdir(data_directory):\n",
    "            if data_file.endswith(\".xlsx\"):\n",
    "                data_path = os.path.join(data_directory, data_file)\n",
    "                df = pd.read_excel(data_path, usecols=columns_of_interest)\n",
    "                df_normalized = normalize_dataframe(df)\n",
    "\n",
    "                tensor_folder_name = 'figure' + os.path.splitext(data_file)[0]\n",
    "                for index, row in df_normalized.iterrows():\n",
    "                    tensor_file_name = f\"{tensor_folder_name}_group_{index}.pt\"\n",
    "                    tensor_file_path = os.path.join(tensor_directory, tensor_file_name)\n",
    "                    if os.path.exists(tensor_file_path):\n",
    "                        self.data.append((tensor_file_path, row.drop('CO'), row['CO']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor_path, numeric_data, co_label = self.data[idx]\n",
    "        image_tensor = torch.load(tensor_path)\n",
    "        return image_tensor, numeric_data.values.astype('float32'), co_label\n",
    "\n",
    "    \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建Dataloader 用Dataloader加载数据 Dataloader将数据输入网络进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入数值网络结构体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "# 自定义数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_directory, columns_of_interest):\n",
    "        self.data = []\n",
    "        for data_file in os.listdir(data_directory):\n",
    "            if data_file.endswith(\".xlsx\"):\n",
    "                data_path = os.path.join(data_directory, data_file)\n",
    "                df = pd.read_excel(data_path, usecols=columns_of_interest)\n",
    "                df_normalized = normalize_dataframe(df)  \n",
    "                for _, row in df_normalized.iterrows():\n",
    "                    numeric_data = row.drop('CO').astype(float)\n",
    "                    co_label = row['CO'].astype(float)\n",
    "                    self.data.append((numeric_data, co_label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        numeric_data, co_label = self.data[idx]\n",
    "        numeric_data = torch.tensor(numeric_data.values, dtype=torch.float32)\n",
    "        co_label = torch.tensor(co_label, dtype=torch.float32).unsqueeze(0)\n",
    "        return numeric_data, co_label\n",
    "\n",
    "class NumericNetwork(nn.Module):\n",
    "    def __init__(self, numeric_features):\n",
    "        super(NumericNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(numeric_features, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, numeric_data):\n",
    "        output = self.fc(numeric_data)\n",
    "        return output\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "# 定义模型训练相关的工具函数\n",
    "def print_gradients(net):\n",
    "    for name, param in net.named_parameters():\n",
    "        if param.requires_grad and param.grad is not None:\n",
    "            print(f'{name} gradient: {param.grad.data.norm(2)}')\n",
    "\n",
    "\n",
    "dataset = CustomDataset(data_directory, columns_of_interest)\n",
    "data_loader = DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# K折交叉\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Starting fold {fold + 1}\")\n",
    "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=20, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=20, shuffle=False)\n",
    "\n",
    "    model = NumericNetwork(numeric_features=len(columns_of_interest) - 1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "\n",
    "print(model)\n",
    "\n",
    "num_epochs = 5000\n",
    "max_grad_norm = 0.01  # 设置梯度裁剪的最大范数 防止梯度爆炸\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0  #损失函数计数器\n",
    "    for batch_idx, (numeric_data, co_label) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(numeric_data)\n",
    "        loss = criterion(outputs, co_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}, Batch {batch_idx + 1}, Loss: {loss.item()}\")\n",
    "        print(\"Input data:\", numeric_data)\n",
    "        print(\"Labels:\", co_label)\n",
    "    print(f\"Fold {fold + 1}, Epoch {epoch + 1}, Average Epoch Loss: {epoch_loss / len(train_loader)}\")\n",
    "    \n",
    "\n",
    "torch.save(model.state_dict(), f'model_weights_fold_{fold + 1}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "model_example = NumericNetwork(numeric_features=10) \n",
    "\n",
    "\n",
    "example_input = torch.randn(10, 10)\n",
    "\n",
    "output = model_example(example_input)\n",
    "\n",
    "\n",
    "viz_graph = make_dot(output, params=dict(list(model_example.named_parameters()) + [('input', example_input)]))\n",
    "\n",
    "\n",
    "viz_graph.render(\"numeric_network_graph\", format=\"png\")\n",
    "\n",
    "\n",
    "os.path.exists(\"numeric_network_graph.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#网络训练好之后 使用网络进行预测\n",
    "#关闭梯度\n",
    "#张量数据输入 Dataloader\n",
    "all_data_loader = DataLoader(dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "with torch.no_grad():\n",
    "    for numeric_data, co_label in all_data_loader:\n",
    "        outputs = model(numeric_data)\n",
    "        all_predictions.extend(outputs.view(-1).tolist())\n",
    "        all_actuals.extend(co_label.view(-1).tolist())\n",
    "\n",
    "#评估\n",
    "r2 = r2_score(all_actuals, all_predictions)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "#绘图\n",
    "plt.scatter(all_actuals, all_predictions, alpha=0.5)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual Values\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
